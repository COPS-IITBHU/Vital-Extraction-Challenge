{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfa0961-cdde-415d-8138-15c1f1489387",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install albumentations\n",
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d516103f-ddc2-41be-8d56-e12d9d41275d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "import cv2\n",
    "import cv2 as cv\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "import torchmetrics\n",
    "from Dataloaders import supervised_loader, test_loader, supervised_train_transform, test_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7b8a8a3-960a-4327-b697-6992b79df55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30aedfba-4dd9-454d-98d2-bbb1c7c6f30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=1,                      # model output channels (number of classes in your dataset)\n",
    ")\n",
    "\n",
    "model = model.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a236e03e-67bb-420c-8e65-dda3c6abecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 3e-5\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 50\n",
    "NUM_WORKERS = 2\n",
    "IMAGE_HEIGHT = 736 \n",
    "IMAGE_WIDTH = 1280 \n",
    "PIN_MEMORY = True\n",
    "LOAD_MODEL = False\n",
    "TRAIN_IMG_DIR = \"segmentation_data/train_imgs\"\n",
    "TRAIN_MASK_DIR = \"segmentation_data/train_masks\"\n",
    "VAL_IMG_DIR = \"segmentation_data/val_imgs\"\n",
    "VAL_MASK_DIR = \"segmentation_data/val_masks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64053b62-2282-494d-ba9d-102b8cc22cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8286e9a-7dba-48e2-9fa2-89d355e9bd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_data_size = 250\n",
    "# ranset = set()\n",
    "# while (len(ranset) <= val_data_size):\n",
    "#     ranset.add(np.random.randint(0, 2001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "843f2151-ad91-4a63-9abd-e3eefbaa7127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# import os\n",
    "\n",
    "# imlis = os.listdir(\"images\")\n",
    "# lablis = os.listdir(\"thims\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d051b4d-a61c-4d70-b74b-9627918d3c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in ranset:\n",
    "#     shutil.move(f\"images/{imlis[i]}\", \"val_im\")\n",
    "#     shutil.move(f\"thims/{lablis[i]}\", \"val_lab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ac25e2e-f3f6-45d0-ad6d-230b5dd94fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading dataloaders\n",
    "\n",
    "train_data_loader = supervised_loader(image_dir = TRAIN_IMG_DIR, mask_dir= TRAIN_MASK_DIR,\n",
    "                                      transform=supervised_train_transform, batch_size=BATCH_SIZE, shuffle=True, num_workers=4,\n",
    "                                      shape = (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "\n",
    "val_data_loader = supervised_loader(image_dir = VAL_IMG_DIR, mask_dir= VAL_MASK_DIR,\n",
    "                                      transform=test_transform, batch_size=BATCH_SIZE, shuffle=False, num_workers = 4,\n",
    "                                      shape = (IMAGE_WIDTH, IMAGE_HEIGHT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21f1b7d2-2322-4bb7-be2b-d5f643feada6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch - 1, Training_Loss - 0.351, Train_mIOU - 0.8809, Training_Loss - 0.2618, val_mIOU - 0.9725\n",
      "Validation mIOU increased from 0 to 0.9724969005584717, Saving Model....\n",
      " Epoch - 2, Training_Loss - 0.2337, Train_mIOU - 0.9772, Training_Loss - 0.1998, val_mIOU - 0.9836\n",
      " Epoch - 3, Step - 48/225, Training_Loss - 0.1981, Train_mIOU - 0.9827\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     32\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 33\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m     36\u001b[0m iou_train \u001b[38;5;241m=\u001b[39m iou_fn(predictions\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m), ((targets \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:338\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 338\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:284\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    283\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf_per_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    285\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:284\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    283\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    285\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iou_fn = torchmetrics.classification.JaccardIndex(task = 'binary', threshold = 0., num_classes = 2)\n",
    "\n",
    "epochs = (range(NUM_EPOCHS))\n",
    "\n",
    "val_loss = []\n",
    "train_loss = []\n",
    "\n",
    "train_iou = []\n",
    "val_iou = []\n",
    "\n",
    "max_val_iou = 0\n",
    "for epoch in epochs:\n",
    "    \n",
    "    total_val_loss = 0\n",
    "    total_train_loss = 0\n",
    "    total_train_iou = 0\n",
    "    total_val_iou = 0\n",
    "    \n",
    "    ## training part\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(train_data_loader):\n",
    "        data = data.to(device=DEVICE)\n",
    "        targets = targets.float().unsqueeze(1).to(device=DEVICE)\n",
    "\n",
    "        # forward\n",
    "        with torch.cuda.amp.autocast():\n",
    "            predictions = model(data)\n",
    "            loss = loss_fn(predictions, targets)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        iou_train = iou_fn(predictions.to(\"cpu\"), ((targets > 0)*1).to(\"cpu\"))\n",
    "        total_train_iou += iou_train.item()\n",
    "        # loop.set_postfix(loss=loss.item(), iou_loss = iou_train_loss)\n",
    "        total_train_loss += loss.item()\n",
    "        print(f\" Epoch - {epoch+1}, Step - {batch_idx+1}/{len(train_data_loader)}, Training_Loss - {round(total_train_loss/(batch_idx+1), 4)}, Train_mIOU - {round(total_train_iou/(batch_idx+1), 4)}\", end=\"\\r\")\n",
    "    total_train_loss = total_train_loss/(batch_idx+1)\n",
    "    total_train_iou = total_train_iou/(batch_idx+1)\n",
    "    train_loss.append(total_train_loss)\n",
    "    train_iou.append(total_train_iou)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, targets) in enumerate(val_data_loader):\n",
    "            data = data.to(device=DEVICE)\n",
    "            targets = targets.float().unsqueeze(1).to(device=DEVICE)\n",
    "\n",
    "            predictions = model(data)\n",
    "            loss = loss_fn(predictions, targets)\n",
    "            total_val_loss += loss.item()\n",
    "            iou_val = iou_fn(predictions.to(\"cpu\"), ((targets > 0)*1).to(\"cpu\"))\n",
    "            total_val_iou += iou_val.item()\n",
    "            # val_loop.set_postfix(val_loss=loss.item(), iou_loss = iou_val_loss)\n",
    "    total_val_loss = total_val_loss/(batch_idx+1)\n",
    "    total_val_iou = total_val_iou/(batch_idx+1)\n",
    "    val_loss.append(total_val_loss)\n",
    "    val_iou.append(total_val_iou)\n",
    "    print(f\" Epoch - {epoch+1}, Training_Loss - {round(total_train_loss, 4)}, Train_mIOU - {round(total_train_iou, 4)}, Training_Loss - {round(total_val_loss, 4)}, val_mIOU - {round(total_val_iou, 4)}\")\n",
    "\n",
    "    if total_val_iou>max_val_iou:\n",
    "        print(f\"Validation mIOU increased from {max_val_iou} to {total_val_iou}, Saving Model....\")\n",
    "        torch.save(model.state_dict(), \"best_model.ckpt\")\n",
    "        max_val_iou = total_val_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f362f0-70f9-4db4-a29f-e81c723be43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss, label=\"train-loss\")\n",
    "plt.plot(val_loss, label=\"validation-loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"results/supervised_unet_loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cb6fa7-a77d-427c-87f1-95f967a62f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_iou, label = \"training-mIOU\")\n",
    "plt.plot(val_iou, label = \"validation-mIOU\")\n",
    "plt.legend()\n",
    "plt.savefig(\"results/supervised_unet_miou.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2234437-7eb1-4c24-a699-53ce9efa2bee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:notebook] *",
   "language": "python",
   "name": "conda-env-notebook-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
